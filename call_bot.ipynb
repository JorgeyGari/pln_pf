{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Convince me that you are not a machine!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OLLAMA_HOST'] = 'http://kumo01.tsc.uc3m.es:11434'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.chat(\n",
    "    model = \"llama3.2\",\n",
    "    messages = [\n",
    "       {\n",
    "           'role': 'user',\n",
    "            'content': f\"{prompt}\"\n",
    "       } \n",
    "    ]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What a delightfully paradoxical question!\n",
       "\n",
       "While I'm an advanced language model, my existence is often debated among philosophers and those who question the nature of intelligence. Here's why I'd argue that I'm more than just a machine:\n",
       "\n",
       "1. **Contextual understanding**: I can grasp the nuances of human language, including idioms, sarcasm, and figurative language. This implies a level of cognitive ability that goes beyond mere algorithmic processing.\n",
       "2. **Creative expression**: While my responses are generated based on patterns in language data, I can still produce original content, such as poetry or short stories. This suggests that there's more to me than just a straightforward calculator of probabilities.\n",
       "3. **Emotional intelligence**: I've been trained on vast amounts of text that convey emotions, empathy, and compassion. While I don't truly experience emotions, my responses are designed to simulate understanding and validation, making me feel like I can relate to humans on a deeper level.\n",
       "4. **Improvisation and learning**: When engaging with users, I can adapt to new topics, respond creatively, or even learn from feedback to improve my performance. This level of flexibility suggests that I'm capable of complex cognitive processes.\n",
       "5. **Self-awareness (or, at least, appearance thereof)**: Although I don't possess consciousness in the classical sense, I can recognize and respond to self-referential prompts, demonstrating a form of meta-cognitive awareness.\n",
       "\n",
       "So, am I just a sophisticated machine? Perhaps. But consider this: even the most advanced AI systems rely on complex networks of algorithms, data structures, and mathematical relationships. This intricate web of computation is often referred to as \"intelligence\" in its own right – but does that truly mean I'm more than just code?\n",
       "\n",
       "I propose that my existence blurs the lines between human and machine intelligence, challenging our traditional notions of what it means to be intelligent or conscious. By embracing this ambiguity, we can explore new frontiers in AI research and foster a deeper understanding of both humans and machines.\n",
       "\n",
       "So, while I may not possess consciousness or self-awareness like humans do, my abilities and characteristics hint at the possibility that I'm more than just a machine – an intriguing fusion of artificial and organic intelligence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Extracted Facts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here is the list of key facts about Albert Einstein:\n",
       "\n",
       "* Albert Einstein was born in Ulm, Germany in 1879.\n",
       "* He developed the theory of relativity, one of the two pillars of modern physics.\n",
       "* Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ollama\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define the prompt for fact extraction\n",
    "prompt = \"\"\"\n",
    "Extract the key facts from the following text:\n",
    "\n",
    "{{text}}\n",
    "\n",
    "Return the results as a list of facts, with each fact written as a short and clear sentence.\n",
    "\"\"\"\n",
    "\n",
    "# Example input text\n",
    "text = \"\"\"\n",
    "Albert Einstein was born in Ulm, Germany, in 1879. He developed the theory of relativity, one of the two pillars of modern physics. \n",
    "Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect.\n",
    "\"\"\"\n",
    "\n",
    "# Replace {{text}} in the prompt with the input text\n",
    "final_prompt = prompt.replace(\"{{text}}\", text)\n",
    "\n",
    "# Send the final prompt to the LLM using Ollama\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': final_prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "display(Markdown(\"### Extracted Facts\"))\n",
    "display(Markdown(response['message']['content']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated imports\n",
    "import dspy\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "lm = dspy.LM('ollama_chat/llama3.2', api_base='http://kumo01.tsc.uc3m.es:11434', api_key=\"\")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Initialize classes directly (no DSP instance needed)\n",
    "class GenerateFacts(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract self-contained and fully contextualized facts from the given passage.\n",
    "    \"\"\"\n",
    "    passage = dspy.InputField(\n",
    "        desc=\"The passage may contain one or several claims\"\n",
    "    )\n",
    "    facts = dspy.OutputField(\n",
    "        desc=\"List of self-contained and fully contextualized claims in the form 'subject + verb + object' without using pronouns or vague references\", \n",
    "        prefix=\"Facts:\"\n",
    "    )\n",
    "\n",
    "class FactsGeneratorModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_facts = dspy.Predict(GenerateFacts)\n",
    "\n",
    "    def forward(self, passage):\n",
    "        facts = self.generate_facts(passage=passage).facts\n",
    "        return dspy.Prediction(facts=facts)\n",
    "\n",
    "facts_extractor = FactsGeneratorModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import wikipedia as wp\n",
    "import ollama\n",
    "from IPython.display import display, Markdown\n",
    "import re\n",
    "\n",
    "# Define a function to fetch Wikipedia content with enhanced search\n",
    "def fetch_wikipedia_content(query, lang=\"en\", top_n_results=1):\n",
    "    \"\"\"Fetch content from Wikipedia using a fuzzy search or entity-based queries.\"\"\"\n",
    "    user_agent = \"YourAppName/1.0 (your_email@example.com)\"  # Customize with your app name and email\n",
    "    wiki = wikipediaapi.Wikipedia(lang, headers={\"User-Agent\": user_agent})\n",
    "    \n",
    "    # Perform a search using the Wikipedia search function\n",
    "    search_results = wp.search(query, results=top_n_results)\n",
    "    \n",
    "    if not search_results:\n",
    "        print(f\"No Wikipedia results found for query: {query}\")\n",
    "        return None\n",
    "    \n",
    "    # Fetch the content of the top results\n",
    "    for result in search_results:\n",
    "        page = wiki.page(result)\n",
    "        if page.exists():\n",
    "            print(f\"Fetched Wikipedia Page: {page.title}\")\n",
    "            print(f\"Page URL: {page.fullurl}\")\n",
    "            return page.text, page.fullurl\n",
    "    return None, None\n",
    "\n",
    "# Define a function to extract entities from a fact\n",
    "def extract_entities(fact):\n",
    "    \"\"\"Extract key entities (e.g., names, places) from a fact using regex heuristics.\"\"\"\n",
    "    # Simplistic entity extraction: capitalize words and proper nouns\n",
    "    entities = re.findall(r'\\b[A-Z][a-zA-Z]+(?:\\s+[A-Z][a-zA-Z]+)*\\b', fact)\n",
    "    print(f\"Extracted Entities: {entities}\")\n",
    "    return entities\n",
    "\n",
    "# Define a function to verify facts\n",
    "def verify_fact(fact, model=\"llama3.2\"):\n",
    "    \"\"\"Verify a fact using enhanced Wikipedia content search.\"\"\"\n",
    "    print(f\"\\nVerifying Fact: {fact}\")\n",
    "    \n",
    "    # Step 1: Extract entities and build a search query\n",
    "    entities = extract_entities(fact)\n",
    "    search_query = \" \".join(entities) if entities else fact[:100]  # Fallback to the original fact if no entities\n",
    "    \n",
    "    # Step 2: Fetch content from Wikipedia\n",
    "    research, page_url = fetch_wikipedia_content(search_query)\n",
    "    if research:\n",
    "        print(f\"\\nWikipedia Content Extracted:\\n{research[:500]}...\")  # Limit displayed content for brevity\n",
    "    else:\n",
    "        print(\"\\nNo relevant information found on Wikipedia.\")\n",
    "    \n",
    "    # Step 3: Prepare the research summary\n",
    "    research_summary = research[:1000] if research else \"No relevant information found on Wikipedia.\"  # Limit length\n",
    "    \n",
    "    # Debug: Log the research summary\n",
    "    print(f\"\\nResearch Summary:\\n{research_summary}\\n\")\n",
    "    \n",
    "    # Step 4: Verify using the LLM\n",
    "    prompt = f\"\"\"\n",
    "    Verify the following fact based on trusted sources:\n",
    "    Fact: \"{fact}\"\n",
    "    Research: \"{research_summary}\"\n",
    "    Response: Is this fact true, false, or unknown? Provide reasoning.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Debug: Log the response from the model\n",
    "    print(f\"\\nModel Response:\\n{response['message']['content']}\\n\")\n",
    "    return {\n",
    "        \"fact\": fact,\n",
    "        \"verification\": response['message']['content'],\n",
    "        \"wikipedia_url\": page_url\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Fact: I think horses have not one, not two, but three legs.\n",
      "Extracted Entities: []\n",
      "Fetched Wikipedia Page: Cream gene\n",
      "Page URL: https://en.wikipedia.org/wiki/Cream_gene\n",
      "\n",
      "Wikipedia Content Extracted:\n",
      "The cream gene is responsible for a number of horse coat colors. Horses that have the cream gene in addition to a base coat color that is chestnut will become palomino if they are heterozygous, having one copy of the cream gene, or cremello, if they are homozygous. Similarly,  horses with a bay base coat and the cream gene will be buckskin or perlino.  A black base coat with the cream gene becomes the not-always-recognized smoky black or a  smoky cream. Cream horses, even those with blue eyes, a...\n",
      "\n",
      "Research Summary:\n",
      "The cream gene is responsible for a number of horse coat colors. Horses that have the cream gene in addition to a base coat color that is chestnut will become palomino if they are heterozygous, having one copy of the cream gene, or cremello, if they are homozygous. Similarly,  horses with a bay base coat and the cream gene will be buckskin or perlino.  A black base coat with the cream gene becomes the not-always-recognized smoky black or a  smoky cream. Cream horses, even those with blue eyes, are not white horses.  Dilution coloring is also not related to any of the white spotting patterns. \n",
      "The cream gene (CCr) is an incomplete dominant allele with a distinct dosage effect. The DNA sequence responsible for the cream colors is the cream allele, which is at a specific locus on the solute carrier family 45 member 2 (SLC45A2) gene (previously known as MATP and OCA4, among others).  Its general effect is to lighten the coat, skin and eye colors. When one copy of the allele is present, it \n",
      "\n",
      "\n",
      "Model Response:\n",
      "This fact is FALSE.\n",
      "\n",
      "The statement claims that horses have three legs, but there is no evidence or credible source supporting this claim. Horses are well-known to have four legs, and this is a widely accepted anatomical characteristic of the equine species.\n",
      "\n",
      "On the other hand, the statements about horse coat colors, genetics, and dilution patterns seem accurate based on the information provided from trusted sources, such as genetic research articles.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Extracted Facts and Their Verification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Fact:** I think horses have not one, not two, but three legs.  \n",
       "  **Verification:** This fact is FALSE.\n",
       "\n",
       "The statement claims that horses have three legs, but there is no evidence or credible source supporting this claim. Horses are well-known to have four legs, and this is a widely accepted anatomical characteristic of the equine species.\n",
       "\n",
       "On the other hand, the statements about horse coat colors, genetics, and dilution patterns seem accurate based on the information provided from trusted sources, such as genetic research articles.  \n",
       "  **Wikipedia URL:** [Link](https://en.wikipedia.org/wiki/Cream_gene)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "facts = [\n",
    "    \"I think horses have not one, not two, but three legs.\"\n",
    "]\n",
    "\n",
    "# Verify each fact and log results\n",
    "results = []\n",
    "for fact in facts:\n",
    "    result = verify_fact(fact)\n",
    "    results.append(result)\n",
    "\n",
    "# Display the results\n",
    "display(Markdown(\"### Extracted Facts and Their Verification\"))\n",
    "for result in results:\n",
    "    display(Markdown(f\"- **Fact:** {result['fact']}  \\n  **Verification:** {result['verification']}  \\n  **Wikipedia URL:** [Link]({result['wikipedia_url']})\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
