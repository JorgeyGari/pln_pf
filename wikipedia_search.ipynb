{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigar en Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['chocloate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import wikipedia\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query, language='en', top_n=5):\n",
    "    wiki = wikipediaapi.Wikipedia('MyProjectName (merlin@example.com)', language)\n",
    "    search_results = wiki.search(query)\n",
    "\n",
    "    if not search_results:\n",
    "        return f\"No results found for '{query}'.\"\n",
    "    \n",
    "    matches = process.extract(query, search_results, limit=top_n)\n",
    "    results = []\n",
    "    for title, score in matches:\n",
    "        page = wiki.page(title)\n",
    "        if page.exists():\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'summary': page.summary[:200] + '...' if len(page.summary) > 200 else  page.summary,\n",
    "                'score': score\n",
    "            }) \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query, top_n=5):\n",
    "    try:\n",
    "        search_results = wikipedia.search(query)\n",
    "\n",
    "        if not search_results:\n",
    "            return f\"No results found for '{query}'.\"\n",
    "        \n",
    "\n",
    "        results = []\n",
    "\n",
    "        matches = process.extract(query, search_results, limit=top_n)\n",
    "\n",
    "        for title, score in matches:\n",
    "            try:\n",
    "                page = wikipedia.page(title)\n",
    "                results.append({\n",
    "                    'title': title,\n",
    "                    'summary': page.summary[:200] + '...' if len(page.summary) > 200 else page.summary,\n",
    "                    'score': score \n",
    "                })\n",
    "            except wikipedia.DisambiguationError as e:\n",
    "                results.append({\n",
    "                    'title': title,\n",
    "                    'summary': \"Disambiguation page. Options: \" + \", \".join(e.options[:5] ) + \"...\",\n",
    "                    'score': score\n",
    "                })\n",
    "            except wikipedia.PageError:\n",
    "                results.append({\n",
    "                    'title': title,\n",
    "                    'summary': \"Page not found.\",\n",
    "                    'score': score\n",
    "                } )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Chocolate', 'summary': 'Chocolate is a food made from roasted and ground cocoa beans that can be a liquid, solid, or paste, either on its own or as a flavoring in other foods. The cacao tree has been used as a source of food...', 'score': 100}, {'title': 'Hot chocolate', 'summary': 'Hot chocolate, also known as hot cocoa or drinking chocolate, is a heated drink consisting of shaved or melted chocolate or cocoa powder, heated milk or water, and usually a sweetener. It is often gar...', 'score': 95}, {'title': 'White chocolate', 'summary': 'White chocolate is a form of chocolate made of cocoa butter, sugar and milk. Unlike milk and dark chocolate, it does not contain cocoa solids, which darken the chocolate. White chocolate has an ivory ...', 'score': 90}, {'title': 'Dubai chocolate', 'summary': \"Dubai chocolate is a chocolate bar with a filling made of kadayif (knafeh) and pistachio. It was first created by Fix Dessert Chocolatier in Dubai in 2022, branded as Can't Get Knafeh of It. This prod...\", 'score': 90}, {'title': 'Chocolate truffle', 'summary': 'A chocolate truffle is a French chocolate confectionery traditionally made with a chocolate ganache centre and coated in cocoa powder, coconut, or chopped nuts. A chocolate truffle is handrolled into ...', 'score': 90}]\n"
     ]
    }
   ],
   "source": [
    "query = \"chocolate\"\n",
    "results = search_wikipedia(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "results = search_wikipedia(query)\n",
    "\n",
    "# Print the section titles of the first search result\n",
    "page = wikipedia.page(results[0]['title'])\n",
    "print(page.sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%%python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import spacy\n",
    "import wikipediaapi\n",
    "import re\n",
    "from typing import List, Optional\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.chunk import tree2conlltags\n",
    "\n",
    "# Initialize the NLP tool (spaCy or NLTK for entity extraction)\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # You can switch to a different model if needed\n",
    "wiki_wiki = wikipediaapi.Wikipedia('MyProjectName', 'en')\n",
    "\n",
    "# Step 1: Define the Pydantic data models\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    titles: List[str]\n",
    "\n",
    "# Step 2: Function to extract entities from the query using NLP\n",
    "def extract_entities(query: str) -> List[str]:\n",
    "    doc = nlp(query)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Step 3: Function to search Wikipedia for entities and return relevant titles\n",
    "def search_wikipedia_for_entities(entities: List[str]) -> List[str]:\n",
    "    titles = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        search_results = wiki_wiki.search(entity, results=3)  # Limiting to top 3 results\n",
    "        titles.extend(search_results)  # Add titles to the list\n",
    "    \n",
    "    return titles\n",
    "\n",
    "# Step 4: Chain function\n",
    "def process_query(query: str) -> QueryResponse:\n",
    "    # Extract entities\n",
    "    entities = extract_entities(query)\n",
    "    \n",
    "    # If no entities found, return an empty response\n",
    "    if not entities:\n",
    "        return QueryResponse(titles=[])\n",
    "    \n",
    "    # Search Wikipedia for entities\n",
    "    titles = search_wikipedia_for_entities(entities)\n",
    "    \n",
    "    # Return the response with titles\n",
    "    return QueryResponse(titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles=['Mercury', 'Mercury (planet)', 'Freddie Mercury', 'Solar System', 'Formation and evolution of the Solar System', 'Fictional planets of the Solar System']\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import spacy\n",
    "import wikipedia\n",
    "from typing import List, Optional\n",
    "\n",
    "# Initialize the NLP tool (spaCy)\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # You can switch to a different model if needed\n",
    "\n",
    "# Step 1: Define the Pydantic data models\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    titles: List[str]\n",
    "\n",
    "# Step 2: Function to extract entities from the query using NLP\n",
    "def extract_entities(query: str) -> List[str]:\n",
    "    doc = nlp(query)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Step 3: Function to search Wikipedia for entities and return relevant titles\n",
    "def search_wikipedia_for_entities(entities: List[str]) -> List[str]:\n",
    "    titles = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        search_results = wikipedia.search(entity, results=3)  # Limiting to top 3 results\n",
    "        titles.extend(search_results)  # Add titles to the list\n",
    "    \n",
    "    return titles\n",
    "\n",
    "# Step 4: Chain function\n",
    "def process_query(query: str) -> QueryResponse:\n",
    "    # Extract entities\n",
    "    entities = extract_entities(query)\n",
    "    \n",
    "    # If no entities found, return an empty response\n",
    "    if not entities:\n",
    "        return QueryResponse(titles=[])\n",
    "    \n",
    "    # Search Wikipedia for entities\n",
    "    titles = search_wikipedia_for_entities(entities)\n",
    "    \n",
    "    # Return the response with titles\n",
    "    return QueryResponse(titles=titles)\n",
    "\n",
    "# Example usage\n",
    "query = \"Mercury is the smallest planet in the Solar System.\"\n",
    "response = process_query(query)\n",
    "\n",
    "# Displaying the result\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
